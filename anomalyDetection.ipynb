{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kRbZa2-x7I4S"
      },
      "source": [
        "# Environment & Libraries Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "LmMWqfYR7Bre"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.preprocessing import MinMaxScaler, StandardScaler, LabelEncoder\n",
        "from sklearn.ensemble import RandomForestClassifier, IsolationForest\n",
        "from mlxtend.classifier import StackingClassifier\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from sklearn.metrics import classification_report, confusion_matrix, ConfusionMatrixDisplay\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from imblearn.under_sampling import RandomUnderSampler\n",
        "from collections import Counter\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models, optimizers\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.metrics import accuracy_score, balanced_accuracy_score, average_precision_score\n",
        "from google.colab import drive\n",
        "from imblearn.pipeline import Pipeline\n",
        "from collections import Counter\n",
        "import joblib\n",
        "import gradio as gr"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nqlMoVT27PSy"
      },
      "source": [
        "## Mounting Google Drive\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6zYxWjZ87Yq0"
      },
      "outputs": [],
      "source": [
        "drive.mount('/content/drive', force_remount=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BLKt32cC7fMg"
      },
      "source": [
        "# Data Loading and Preprocesing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "AvqQwP0M7h88"
      },
      "outputs": [],
      "source": [
        "# Load datasets from specified CSV files\n",
        "df1 = pd.read_csv('/content/drive/MyDrive/Magisterka/Dataset/l1-nondoh.csv')\n",
        "df2 = pd.read_csv('/content/drive/MyDrive/Magisterka/Dataset/l2-benign.csv')\n",
        "df3 = pd.read_csv('/content/drive/MyDrive/Magisterka/Dataset/l2-malicious.csv')\n",
        "\n",
        "# Align columns before concatenation\n",
        "common_cols = list(set(df1.columns) & set(df2.columns) & set(df3.columns))\n",
        "df1 = df1[common_cols]\n",
        "df2 = df2[common_cols]\n",
        "df3 = df3[common_cols]\n",
        "\n",
        "# Concatenate the dataframes into a single dataframe\n",
        "df = pd.concat([df1, df2, df3], ignore_index=True)\n",
        "\n",
        "print(df.info)\n",
        "\n",
        "# Remove duplicate rows and reset index\n",
        "df = df.drop_duplicates().reset_index(drop=True)\n",
        "\n",
        "# Shuffle the combined dataframe randomly\n",
        "shuffled_df = df.sample(frac=1, random_state=42)\n",
        "df = shuffled_df.reset_index(drop=True)\n",
        "\n",
        "# Drop high-cardinality or identifier columns that are not useful for modeling\n",
        "drop_cols = ['SourceIP', 'DestinationIP', 'SourcePort', 'DestinationPort', 'TimeStamp']\n",
        "df = df.drop(columns=[col for col in drop_cols if col in df.columns])\n",
        "\n",
        "# Handle missing values by dropping rows with any missing values\n",
        "df = df.dropna(axis=0)\n",
        "\n",
        "# Separate features (X) and the target label (y)\n",
        "X = df.drop('Label', axis=1)\n",
        "y = df['Label']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "EEq18wLKAIKP"
      },
      "outputs": [],
      "source": [
        "# Create a copy of the dataframe to include the 'Label' column\n",
        "df_02 = df.copy()\n",
        "\n",
        "# Initialize LabelEncoder\n",
        "le = LabelEncoder()\n",
        "\n",
        "# Encode the 'Label' column into numerical representations\n",
        "df_02['Label'] = le.fit_transform(df_02['Label'])\n",
        "\n",
        "# Display the dataframe with the encoded labels\n",
        "print(df_02.head()) # Using head() to avoid printing the entire large dataframe"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "Ut5KEWFeCH2f"
      },
      "outputs": [],
      "source": [
        "# Assign the 'Label' column of the encoded dataframe to the target variable y\n",
        "y = df_02['Label']\n",
        "\n",
        "# Display the target variable\n",
        "y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lyWMJHM9BYd5"
      },
      "outputs": [],
      "source": [
        "# Print the mapping of original labels to their encoded numerical representations\n",
        "label_mapping = dict(zip(le.classes_, le.transform(le.classes_)))\n",
        "print(\"Label mapping:\", label_mapping)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RK4yN0tQ75V6"
      },
      "source": [
        "# Data Analysis"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hqwPt2d78fA6"
      },
      "source": [
        "## Dataset Overview"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9qyj7rJS777b"
      },
      "outputs": [],
      "source": [
        "# General info about the dataframe (data types, non-null values, memory usage)\n",
        "print(df.info())\n",
        "\n",
        "# Descriptive statistics for numerical columns\n",
        "print(df.describe())\n",
        "\n",
        "# Visualize the distribution of the target classes to check for imbalance\n",
        "sns.countplot(data=df, x='Label')\n",
        "plt.title('Distribution of Target Classes')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iJHIUIzU8mRj"
      },
      "source": [
        "## Feature Analysis & Correlation\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zMXmDkMM8ozq"
      },
      "outputs": [],
      "source": [
        "# Plot histograms for all features\n",
        "features = [col for col in df.columns if col != 'Label']\n",
        "\n",
        "df[features].hist(bins=30, figsize=(18, 18), color='#4287f5', grid=False)\n",
        "plt.tight_layout()\n",
        "plt.suptitle('Feature Histograms', fontsize=20, y=1.02)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BT98ftvl9Y4g"
      },
      "source": [
        "## Correlation Matrix and Heatmap"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7aTdxjoH9mgw"
      },
      "outputs": [],
      "source": [
        "# Calculate the correlation matrix\n",
        "corr = df_02.corr()\n",
        "\n",
        "# Plot the heatmap\n",
        "plt.figure(figsize=(14, 12))\n",
        "sns.heatmap(corr, annot=False, cmap='coolwarm', linewidths=0.5)\n",
        "plt.title('Feature Correlation Heatmap')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "24FpaQ4_LiMn"
      },
      "source": [
        "# Feature Engineering"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rkB_5Z0tKL4e"
      },
      "source": [
        "### Raw Data Split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pc5G9hJGZVhC"
      },
      "outputs": [],
      "source": [
        "# Features separation (X) and target (y) after initial preprocessing\n",
        "X = df_02.drop('Label', axis=1)\n",
        "y = df_02['Label']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dlATFiNS-VqY"
      },
      "outputs": [],
      "source": [
        "# Data split into training and testing (80:20)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZFgH_z8kKf6o"
      },
      "source": [
        "## Oversampling (SMOTE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uv9Eow35Klaz"
      },
      "outputs": [],
      "source": [
        "# Apply SMOTE oversampling\n",
        "oversampler = SMOTE(random_state=42)\n",
        "X_train_oversampled, y_train_oversampled = oversampler.fit_resample(X_train, y_train)\n",
        "\n",
        "# Class distribution before and after oversampling\n",
        "print(\"Original training set shape:\", Counter(y_train))\n",
        "print(\"Resampled training set shape:\", Counter(y_train_oversampled))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oEqTHLSsK68O"
      },
      "source": [
        "## Undersampligng"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uBtPy71DK5p2"
      },
      "outputs": [],
      "source": [
        "# Apply undersampling\n",
        "undersampler = RandomUnderSampler(random_state=42)\n",
        "X_train_downsampled, y_train_downsampled = undersampler.fit_resample(X_train, y_train)\n",
        "print(\"Original training set shape:\", Counter(y_train))\n",
        "print(\"Resampled training set shape:\", Counter(y_train_downsampled))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MkQNYLY493lb"
      },
      "source": [
        "## Hybrid SMOTE + undersampler"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4Yr6muQJ96vq"
      },
      "outputs": [],
      "source": [
        "# Define undersampler\n",
        "undersampler = RandomUnderSampler(sampling_strategy={2: 250000}, random_state=42)\n",
        "\n",
        "# Define oversampler\n",
        "oversampler = SMOTE(sampling_strategy={0: 250000, 1: 250000}, random_state=42)\n",
        "\n",
        "# Combine into pipeline\n",
        "pipeline = Pipeline(steps=[('undersample', undersampler),\n",
        "                           ('oversample', oversampler)])\n",
        "\n",
        "# Apply to training data\n",
        "X_train_balanced, y_train_balanced = pipeline.fit_resample(X_train, y_train)\n",
        "\n",
        "print(\"Original training set shape:\", Counter(y_train))\n",
        "print(\"Resampled training set shape:\", Counter(y_train_balanced))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FRLB-b4XiboB"
      },
      "source": [
        "## Standard Scaler"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3PYcDnqeKFAg"
      },
      "source": [
        "### Standard Scaler Split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Bk7OgWWsSPkT"
      },
      "outputs": [],
      "source": [
        "df_scaled = X.copy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kMtwCYPuJQvR"
      },
      "outputs": [],
      "source": [
        "# Split with reproducibility\n",
        "X_train_std, X_test_std, y_train_std, y_test_std = train_test_split(df_scaled[features], y, test_size=0.2, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2oDklP5aihZi",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "# Apply Standard Scaler\n",
        "scaler = StandardScaler()\n",
        "X_train_std = scaler.fit_transform(X_train)\n",
        "X_test_std  = scaler.transform(X_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "obahtl0pZhmG"
      },
      "source": [
        "# Machine Learning - classification models training"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Models: Random Forest, Naive Bayes, Logistic Regression, XGBoost"
      ],
      "metadata": {
        "id": "HjDhdigvHDzw"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_UeZ2mOVDBzQ"
      },
      "outputs": [],
      "source": [
        "def mapping_confusion_matrix(y_test, y_pred,model,label):\n",
        "\n",
        "    # Label mapping\n",
        "    label_mapping = {0: 'Benign', 1: 'Malicious', 2: 'NonDoH'}\n",
        "\n",
        "    # Compute confusion matrix\n",
        "    cm = confusion_matrix(y_test, y_pred)\n",
        "\n",
        "    # Create label list in the correct order\n",
        "    labels = [label_mapping[i] for i in sorted(label_mapping)]\n",
        "\n",
        "    # Plot confusion matrix\n",
        "    plt.figure(figsize=(6, 5))\n",
        "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
        "                xticklabels=labels, yticklabels=labels)\n",
        "    plt.xlabel(\"Predicted\")\n",
        "    plt.ylabel(\"True\")\n",
        "    plt.title(f\"Confusion Matrix - {model.__class__.__name__} - {label}\")\n",
        "    plt.tight_layout()\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E7vWLUFSJw8w"
      },
      "outputs": [],
      "source": [
        "def train_and_evaluate(X_train, y_train, X_test, y_test, model, label):\n",
        "    # Train model\n",
        "    model.fit(X_train, y_train)\n",
        "\n",
        "    # Predict on test set\n",
        "    y_pred = model.predict(X_test)\n",
        "\n",
        "    # Print evaluation results\n",
        "    print(f\"Label: {label}\")\n",
        "    print(f\"Model: {model.__class__.__name__}\")\n",
        "    print(\"Classification Report:\")\n",
        "    print(classification_report(y_test, y_pred))\n",
        "    print(\"Confusion Matrix:\")\n",
        "    mapping_confusion_matrix(y_test, y_pred, model, label)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Um185Ydc2YPB"
      },
      "outputs": [],
      "source": [
        "# Model list\n",
        "models = [\n",
        "    RandomForestClassifier(random_state=42),\n",
        "    GaussianNB(),\n",
        "    LogisticRegression(max_iter=1000, random_state=42),\n",
        "    XGBClassifier()\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "irFuq5GU2Z1T"
      },
      "outputs": [],
      "source": [
        "# Train and evaluate all models\n",
        "for model in models:\n",
        "    train_and_evaluate(X_train, y_train, X_test, y_test, model, \"Raw Data\")\n",
        "    train_and_evaluate(X_train_std, y_train_std,  X_test_std, y_test_std, model, \"Standard Scaler\")\n",
        "    train_and_evaluate(X_train_oversampled, y_train_oversampled, X_test, y_test, model, \"SMOTE Oversampling\")\n",
        "    train_and_evaluate(X_train_downsampled, y_train_downsampled, X_test, y_test, model, \"Downsampling\")\n",
        "    train_and_evaluate(X_train_balanced, y_train_balanced, X_test, y_test, model, \"Hybrid SMOTE+downsampling\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Machine learning - Neural Networks"
      ],
      "metadata": {
        "id": "pa4AD91cWhGN"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NQqu70hemToY"
      },
      "source": [
        "## Feedforward Neural Network (MLP)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BhyzUqhbBZlq"
      },
      "source": [
        "### Raw data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sMrOAtTEpB1T"
      },
      "outputs": [],
      "source": [
        "y_onehot = to_categorical(y_train, num_classes=3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oOl5XllXmUrD"
      },
      "outputs": [],
      "source": [
        "model = models.Sequential([\n",
        "    layers.Dense(128, activation='relu', input_shape=(X_train.shape[1],)),\n",
        "    layers.Dense(64, activation='relu'),\n",
        "    layers.Dense(3, activation='softmax')\n",
        "])\n",
        "\n",
        "model.compile(optimizer='adam',\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model.fit(X_train, y_onehot, epochs=70, batch_size=1024, validation_split=0.1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TBgKyjlrqd46"
      },
      "outputs": [],
      "source": [
        "y_test_onehot = to_categorical(y_test, num_classes=3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bdRnVAoCqSE5"
      },
      "outputs": [],
      "source": [
        "\n",
        "loss, acc = model.evaluate(X_test, y_test_onehot)\n",
        "print(\"Test accuracy:\", acc)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rItaJ85pqzhz"
      },
      "outputs": [],
      "source": [
        "# Get model predictions\n",
        "y_pred_probs = model.predict(X_test)\n",
        "y_pred = np.argmax(y_pred_probs, axis=1)\n",
        "y_true = np.argmax(y_test_onehot, axis=1)\n",
        "\n",
        "# Confusion matrix\n",
        "cm = confusion_matrix(y_true, y_pred)\n",
        "\n",
        "# Classification report (optional but useful)\n",
        "print(classification_report(y_true, y_pred))\n",
        "\n",
        "# Plot confusion matrix\n",
        "plt.figure(figsize=(6, 5))\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
        "            xticklabels=[f\"Class {i}\" for i in range(3)],\n",
        "            yticklabels=[f\"Class {i}\" for i in range(3)])\n",
        "plt.xlabel(\"Predicted Label\")\n",
        "plt.ylabel(\"True Label\")\n",
        "plt.title(\"Confusion Matrix\")\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wg3P3JWFre0z"
      },
      "outputs": [],
      "source": [
        "# Predict class indices from the model\n",
        "y_pred_probs = model.predict(X_test)\n",
        "y_pred = np.argmax(y_pred_probs, axis=1)\n",
        "\n",
        "y_true = y_test.ravel() if y_test.ndim == 2 else y_test\n",
        "\n",
        "# Define class names based on your label encoding\n",
        "class_names = ['Benign', 'Malicious', 'NonDoH']\n",
        "\n",
        "# Generate confusion matrix\n",
        "cm = confusion_matrix(y_true, y_pred)\n",
        "\n",
        "# Print classification report\n",
        "print(classification_report(y_true, y_pred, target_names=class_names))\n",
        "\n",
        "# Plot confusion matrix\n",
        "plt.figure(figsize=(6, 5))\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
        "            xticklabels=class_names,\n",
        "            yticklabels=class_names)\n",
        "plt.xlabel(\"Predicted Label\")\n",
        "plt.ylabel(\"True Label\")\n",
        "plt.title(\"Confusion Matrix\")\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bSd48KoDDC0_"
      },
      "source": [
        "## Standard Scaler"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gs0RUjLvEEsV"
      },
      "outputs": [],
      "source": [
        "y_onehot = to_categorical(y_train_std, num_classes=3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B_Pp0tlYEEsW"
      },
      "outputs": [],
      "source": [
        "model = models.Sequential([\n",
        "    layers.Dense(128, activation='relu', input_shape=(X_train_std.shape[1],)),\n",
        "    layers.Dense(64, activation='relu'),\n",
        "    layers.Dense(3, activation='softmax')  # 3 classes → softmax output\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam',\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "model.fit(X_train_std, y_onehot, epochs=70, batch_size=1024, validation_split=0.1) #we increased from 20 to 70"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iamfIdpJEEsW"
      },
      "outputs": [],
      "source": [
        "y_test_onehot = to_categorical(y_test_std, num_classes=3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lbtmWGXgEEsX"
      },
      "outputs": [],
      "source": [
        "# Evaluate the model\n",
        "loss, acc = model.evaluate(X_test_std, y_test_onehot)\n",
        "print(\"Test accuracy:\", acc)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C-yaTCFyEEsX"
      },
      "outputs": [],
      "source": [
        "# Get model predictions\n",
        "y_pred_probs = model.predict(X_test_std)\n",
        "y_pred = np.argmax(y_pred_probs, axis=1)         # Convert softmax probs to class indices\n",
        "y_true = np.argmax(y_test_onehot, axis=1)        # Convert one-hot encoded labels to class indices\n",
        "\n",
        "# Confusion matrix\n",
        "cm = confusion_matrix(y_true, y_pred)\n",
        "\n",
        "# Classification report (optional but useful)\n",
        "print(classification_report(y_true, y_pred))\n",
        "\n",
        "# Plot confusion matrix\n",
        "plt.figure(figsize=(6, 5))\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
        "            xticklabels=[f\"Class {i}\" for i in range(3)],\n",
        "            yticklabels=[f\"Class {i}\" for i in range(3)])\n",
        "plt.xlabel(\"Predicted Label\")\n",
        "plt.ylabel(\"True Label\")\n",
        "plt.title(\"Confusion Matrix\")\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TR_X_x9MEEsX"
      },
      "outputs": [],
      "source": [
        "# Predict class indices from the model\n",
        "y_pred_probs = model.predict(X_test_std)\n",
        "y_pred = np.argmax(y_pred_probs, axis=1)\n",
        "\n",
        "y_true = y_test.ravel() if y_test.ndim == 2 else y_test\n",
        "\n",
        "class_names = ['Benign', 'Malicious', 'NonDoH']\n",
        "\n",
        "# Generate confusion matrix\n",
        "cm = confusion_matrix(y_true, y_pred)\n",
        "\n",
        "# Print classification report\n",
        "print(classification_report(y_true, y_pred, target_names=class_names))\n",
        "\n",
        "# Plot confusion matrix\n",
        "plt.figure(figsize=(6, 5))\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
        "            xticklabels=class_names,\n",
        "            yticklabels=class_names)\n",
        "plt.xlabel(\"Predicted Label\")\n",
        "plt.ylabel(\"True Label\")\n",
        "plt.title(\"Confusion Matrix\")\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NGZ-1RhPOXsk"
      },
      "source": [
        "## Downsampling"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z_vjbI4SO60V"
      },
      "outputs": [],
      "source": [
        "y_onehot = to_categorical(y_train_downsampled, num_classes=3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LEIwn2q4O60W"
      },
      "outputs": [],
      "source": [
        "model = models.Sequential([\n",
        "    layers.Dense(128, activation='relu', input_shape=(X_train_downsampled.shape[1],)),\n",
        "    layers.Dense(64, activation='relu'),\n",
        "    layers.Dense(3, activation='softmax')  # 3 classes → softmax output\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam',\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "model.fit(X_train_downsampled, y_onehot, epochs=70, batch_size=1024, validation_split=0.1) #we increased from 20 to 70"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8HoEe6ElO60W"
      },
      "outputs": [],
      "source": [
        "y_test_onehot = to_categorical(y_test, num_classes=3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JaOhhmlVO60W"
      },
      "outputs": [],
      "source": [
        "# Evaluate the model\n",
        "loss, acc = model.evaluate(X_test, y_test_onehot)\n",
        "print(\"Test accuracy:\", acc)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "INJLUguHO60W"
      },
      "outputs": [],
      "source": [
        "# Get model predictions\n",
        "y_pred_probs = model.predict(X_test)\n",
        "y_pred = np.argmax(y_pred_probs, axis=1)\n",
        "y_true = np.argmax(y_test_onehot, axis=1)\n",
        "\n",
        "# Confusion matrix\n",
        "cm = confusion_matrix(y_true, y_pred)\n",
        "\n",
        "# Classification report (optional but useful)\n",
        "print(classification_report(y_true, y_pred))\n",
        "\n",
        "# Plot confusion matrix\n",
        "plt.figure(figsize=(6, 5))\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
        "            xticklabels=[f\"Class {i}\" for i in range(3)],\n",
        "            yticklabels=[f\"Class {i}\" for i in range(3)])\n",
        "plt.xlabel(\"Predicted Label\")\n",
        "plt.ylabel(\"True Label\")\n",
        "plt.title(\"Confusion Matrix\")\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zNn-a_TtO60W"
      },
      "outputs": [],
      "source": [
        "# Predict class indices from the model\n",
        "y_pred_probs = model.predict(X_test)\n",
        "y_pred = np.argmax(y_pred_probs, axis=1)\n",
        "\n",
        "\n",
        "y_true = y_test.ravel() if y_test.ndim == 2 else y_test\n",
        "\n",
        "# Define class names based on your label encoding\n",
        "class_names = ['Benign', 'Malicious', 'NonDoH']\n",
        "\n",
        "# Generate confusion matrix\n",
        "cm = confusion_matrix(y_true, y_pred)\n",
        "\n",
        "# Print classification report\n",
        "print(classification_report(y_true, y_pred, target_names=class_names))\n",
        "\n",
        "# Plot confusion matrix\n",
        "plt.figure(figsize=(6, 5))\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
        "            xticklabels=class_names,\n",
        "            yticklabels=class_names)\n",
        "plt.xlabel(\"Predicted Label\")\n",
        "plt.ylabel(\"True Label\")\n",
        "plt.title(\"Confusion Matrix\")\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bcnum9ORPCaf"
      },
      "source": [
        "## Oversampling"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pAGdcDrTPQ5N"
      },
      "outputs": [],
      "source": [
        "y_onehot = to_categorical(y_train_oversampled, num_classes=3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z9_EivwnPQ5O"
      },
      "outputs": [],
      "source": [
        "model = models.Sequential([\n",
        "    layers.Dense(128, activation='relu', input_shape=(X_train_oversampled.shape[1],)),\n",
        "    layers.Dense(64, activation='relu'),\n",
        "    layers.Dense(3, activation='softmax')  # 3 classes → softmax output\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam',\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "model.fit(X_train_oversampled, y_onehot, epochs=70, batch_size=1024, validation_split=0.1) #we increased from 20 to 70"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fAmHVX-ZPQ5O"
      },
      "outputs": [],
      "source": [
        "y_test_onehot = to_categorical(y_test, num_classes=3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0qE4SwyxPQ5O"
      },
      "outputs": [],
      "source": [
        "# Evaluate the model\n",
        "loss, acc = model.evaluate(X_test, y_test_onehot)\n",
        "print(\"Test accuracy:\", acc)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p0M3pd0HPQ5O"
      },
      "outputs": [],
      "source": [
        "# Get model predictions\n",
        "y_pred_probs = model.predict(X_test)\n",
        "y_pred = np.argmax(y_pred_probs, axis=1)\n",
        "y_true = np.argmax(y_test_onehot, axis=1)\n",
        "\n",
        "# Confusion matrix\n",
        "cm = confusion_matrix(y_true, y_pred)\n",
        "\n",
        "# Classification report (optional but useful)\n",
        "print(classification_report(y_true, y_pred))\n",
        "\n",
        "# Plot confusion matrix\n",
        "plt.figure(figsize=(6, 5))\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
        "            xticklabels=[f\"Class {i}\" for i in range(3)],\n",
        "            yticklabels=[f\"Class {i}\" for i in range(3)])\n",
        "plt.xlabel(\"Predicted Label\")\n",
        "plt.ylabel(\"True Label\")\n",
        "plt.title(\"Confusion Matrix\")\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OWkluWrMPQ5O"
      },
      "outputs": [],
      "source": [
        "# Predict class indices from the model\n",
        "y_pred_probs = model.predict(X_test)\n",
        "y_pred = np.argmax(y_pred_probs, axis=1)\n",
        "\n",
        "y_true = y_test.ravel() if y_test.ndim == 2 else y_test\n",
        "\n",
        "\n",
        "class_names = ['Benign', 'Malicious', 'NonDoH']\n",
        "\n",
        "# Generate confusion matrix\n",
        "cm = confusion_matrix(y_true, y_pred)\n",
        "\n",
        "# Print classification report\n",
        "print(classification_report(y_true, y_pred, target_names=class_names))\n",
        "\n",
        "# Plot confusion matrix\n",
        "plt.figure(figsize=(6, 5))\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
        "            xticklabels=class_names,\n",
        "            yticklabels=class_names)\n",
        "plt.xlabel(\"Predicted Label\")\n",
        "plt.ylabel(\"True Label\")\n",
        "plt.title(\"Confusion Matrix\")\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ltlsNKq-ihtg"
      },
      "source": [
        "# RNN"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "whuiUnGPsoBf"
      },
      "source": [
        "## Raw Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mJ4K40r5rYNk"
      },
      "outputs": [],
      "source": [
        "# Shape: (samples, timesteps=1, features)\n",
        "X_train_rnn = np.asarray(X_train, dtype=np.float32).reshape(X_train.shape[0], 1, X_train.shape[1])\n",
        "X_test_rnn  = np.asarray(X_test,  dtype=np.float32).reshape(X_test.shape[0],  1, X_test.shape[1])\n",
        "\n",
        "# Labels as integers\n",
        "y_train_int = np.asarray(y_train, dtype=np.int32)\n",
        "y_test_int  = np.asarray(y_test,  dtype=np.int32)\n",
        "\n",
        "# RNN model\n",
        "model = models.Sequential([\n",
        "    layers.SimpleRNN(\n",
        "        128,\n",
        "        activation='tanh',\n",
        "        input_shape=(X_train_rnn.shape[1], X_train_rnn.shape[2])\n",
        "    ),\n",
        "    layers.Dense(64, activation='relu'),\n",
        "    layers.Dense(3, activation='softmax')\n",
        "])\n",
        "\n",
        "model.compile(optimizer=Adam(),\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "history = model.fit(\n",
        "    X_train_rnn, y_train_int,\n",
        "    epochs=20,\n",
        "    batch_size=32,\n",
        "    validation_data=(X_test_rnn, y_test_int),\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "# Evaluate\n",
        "loss, acc = model.evaluate(X_test_rnn, y_test_int, verbose=0)\n",
        "print(f\"Test loss: {loss:.4f}\")\n",
        "print(f\"Test accuracy: {acc:.4f}\")\n",
        "\n",
        "# Predict and report\n",
        "y_pred_probs = model.predict(X_test_rnn, verbose=0)\n",
        "y_pred = np.argmax(y_pred_probs, axis=1)\n",
        "y_true = y_test_int\n",
        "\n",
        "print(\"\\nClassification report:\\n\")\n",
        "print(classification_report(y_true, y_pred, digits=4))\n",
        "\n",
        "# Print confusion matrix\n",
        "cm = confusion_matrix(y_true, y_pred)\n",
        "class_names = [f\"Class {i}\" for i in range(3)]\n",
        "\n",
        "plt.figure(figsize=(6, 5))\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
        "            xticklabels=class_names, yticklabels=class_names)\n",
        "plt.xlabel(\"Predicted label\")\n",
        "plt.ylabel(\"True label\")\n",
        "plt.title(\"Confusion Matrix (SimpleRNN)\")\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SnBPXiU2iXy3"
      },
      "source": [
        "## Standar Scaler"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "1yxNZg4diaDn"
      },
      "outputs": [],
      "source": [
        "# Shape: (samples, timesteps=1, features)\n",
        "X_train_rnn = np.asarray(X_train_std, dtype=np.float32).reshape(X_train_std.shape[0], 1, X_train.shape[1])\n",
        "X_test_rnn  = np.asarray(X_test_std,  dtype=np.float32).reshape(X_test_std.shape[0],  1, X_test.shape[1])\n",
        "\n",
        "# Labels as integers\n",
        "y_train_int = np.asarray(y_train, dtype=np.int32)\n",
        "y_test_int  = np.asarray(y_test,  dtype=np.int32)\n",
        "\n",
        "# RNN model\n",
        "model = models.Sequential([\n",
        "    layers.SimpleRNN(\n",
        "        128,\n",
        "        activation='tanh',\n",
        "        input_shape=(X_train_rnn.shape[1], X_train_rnn.shape[2])\n",
        "    ),\n",
        "    layers.Dense(64, activation='relu'),\n",
        "    layers.Dense(3, activation='softmax')\n",
        "])\n",
        "\n",
        "model.compile(optimizer=Adam(),\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "history = model.fit(\n",
        "    X_train_rnn, y_train_int,\n",
        "    epochs=20,\n",
        "    batch_size=32,\n",
        "    validation_data=(X_test_rnn, y_test_int),\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "# Evaluate\n",
        "loss, acc = model.evaluate(X_test_rnn, y_test_int, verbose=0)\n",
        "print(f\"Test loss: {loss:.4f}\")\n",
        "print(f\"Test accuracy: {acc:.4f}\")\n",
        "\n",
        "# Predict & report\n",
        "y_pred_probs = model.predict(X_test_rnn, verbose=0)\n",
        "y_pred = np.argmax(y_pred_probs, axis=1)\n",
        "y_true = y_test_int\n",
        "\n",
        "print(\"\\nClassification report:\\n\")\n",
        "print(classification_report(y_true, y_pred, digits=4))\n",
        "\n",
        "# Print confusion matrix\n",
        "cm = confusion_matrix(y_true, y_pred)\n",
        "class_names = [f\"Class {i}\" for i in range(3)]  # customize if you have real names\n",
        "\n",
        "plt.figure(figsize=(6, 5))\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
        "            xticklabels=class_names, yticklabels=class_names)\n",
        "plt.xlabel(\"Predicted label\")\n",
        "plt.ylabel(\"True label\")\n",
        "plt.title(\"Confusion Matrix (SimpleRNN)\")\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NVF7VLObtLZe"
      },
      "source": [
        "## SMOTE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O1J3Kesmuhn9"
      },
      "outputs": [],
      "source": [
        "# Shape: (samples, timesteps=1, features)\n",
        "X_train_rnn = np.asarray(X_train_oversampled, dtype=np.float32).reshape(X_train_oversampled.shape[0], 1, X_train.shape[1])\n",
        "X_test_rnn  = np.asarray(X_test,  dtype=np.float32).reshape(X_test.shape[0],  1, X_test.shape[1])\n",
        "\n",
        "# Labels as integers\n",
        "y_train_int = np.asarray(y_train_oversampled, dtype=np.int32)\n",
        "y_test_int  = np.asarray(y_test,  dtype=np.int32)\n",
        "\n",
        "# RNN model\n",
        "model = models.Sequential([\n",
        "    layers.SimpleRNN(\n",
        "        128,\n",
        "        activation='tanh',\n",
        "        input_shape=(X_train_rnn.shape[1], X_train_rnn.shape[2])\n",
        "    ),\n",
        "    layers.Dense(64, activation='relu'),\n",
        "    layers.Dense(3, activation='softmax')\n",
        "])\n",
        "\n",
        "model.compile(optimizer=Adam(),\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "history = model.fit(\n",
        "    X_train_rnn, y_train_int,\n",
        "    epochs=20,\n",
        "    batch_size=32,\n",
        "    validation_data=(X_test_rnn, y_test_int),\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "# Evaluate\n",
        "loss, acc = model.evaluate(X_test_rnn, y_test_int, verbose=0)\n",
        "print(f\"Test loss: {loss:.4f}\")\n",
        "print(f\"Test accuracy: {acc:.4f}\")\n",
        "\n",
        "# Predict & report\n",
        "y_pred_probs = model.predict(X_test_rnn, verbose=0)\n",
        "y_pred = np.argmax(y_pred_probs, axis=1)\n",
        "y_true = y_test_int\n",
        "\n",
        "print(\"\\nClassification report:\\n\")\n",
        "print(classification_report(y_true, y_pred, digits=4))\n",
        "\n",
        "# Confusion matrix\n",
        "cm = confusion_matrix(y_true, y_pred)\n",
        "class_names = [f\"Class {i}\" for i in range(3)]  # customize if you have real names\n",
        "\n",
        "plt.figure(figsize=(6, 5))\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
        "            xticklabels=class_names, yticklabels=class_names)\n",
        "plt.xlabel(\"Predicted label\")\n",
        "plt.ylabel(\"True label\")\n",
        "plt.title(\"Confusion Matrix (SimpleRNN)\")\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ikwwxIy_z98g"
      },
      "source": [
        "## Downsampling"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zeVnXEqp0cGs"
      },
      "outputs": [],
      "source": [
        "# Shape: (samples, timesteps=1, features)\n",
        "X_train_rnn = np.asarray(X_train_downsampled, dtype=np.float32).reshape(X_train_downsampled.shape[0], 1, X_train.shape[1])\n",
        "X_test_rnn  = np.asarray(X_test,  dtype=np.float32).reshape(X_test.shape[0],  1, X_test.shape[1])\n",
        "\n",
        "# Labels as integers\n",
        "y_train_int = np.asarray(y_train_downsampled, dtype=np.int32)\n",
        "y_test_int  = np.asarray(y_test,  dtype=np.int32)\n",
        "\n",
        "# RNN model\n",
        "model = models.Sequential([\n",
        "    layers.SimpleRNN(\n",
        "        128,\n",
        "        activation='tanh',\n",
        "        input_shape=(X_train_rnn.shape[1], X_train_rnn.shape[2])\n",
        "    ),\n",
        "    layers.Dense(64, activation='relu'),\n",
        "    layers.Dense(3, activation='softmax')\n",
        "])\n",
        "\n",
        "model.compile(optimizer=Adam(),\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "history = model.fit(\n",
        "    X_train_rnn, y_train_int,\n",
        "    epochs=20,\n",
        "    batch_size=32,\n",
        "    validation_data=(X_test_rnn, y_test_int),\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "# Evaluate\n",
        "loss, acc = model.evaluate(X_test_rnn, y_test_int, verbose=0)\n",
        "print(f\"Test loss: {loss:.4f}\")\n",
        "print(f\"Test accuracy: {acc:.4f}\")\n",
        "\n",
        "# Predict & Report\n",
        "y_pred_probs = model.predict(X_test_rnn, verbose=0)\n",
        "y_pred = np.argmax(y_pred_probs, axis=1)\n",
        "y_true = y_test_int\n",
        "\n",
        "print(\"\\nClassification report:\\n\")\n",
        "print(classification_report(y_true, y_pred, digits=4))\n",
        "\n",
        "# Print confusion matrix\n",
        "cm = confusion_matrix(y_true, y_pred)\n",
        "class_names = [f\"Class {i}\" for i in range(3)]\n",
        "plt.figure(figsize=(6, 5))\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
        "            xticklabels=class_names, yticklabels=class_names)\n",
        "plt.xlabel(\"Predicted label\")\n",
        "plt.ylabel(\"True label\")\n",
        "plt.title(\"Confusion Matrix (SimpleRNN)\")\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CY5hM5JRuQsl"
      },
      "source": [
        "# LSTM"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zJ6qtzPkB58j"
      },
      "source": [
        "## Raw Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3U7XePl2B9_y"
      },
      "outputs": [],
      "source": [
        "X_train_lstm = np.asarray(X_train, dtype=np.float32).reshape(X_train.shape[0], 1, X_train.shape[1])\n",
        "X_test_lstm  = np.asarray(X_test,  dtype=np.float32).reshape(X_test.shape[0],  1, X_test.shape[1])\n",
        "\n",
        "\n",
        "y_train_int = np.asarray(y_train, dtype=np.int32)\n",
        "y_test_int  = np.asarray(y_test,  dtype=np.int32)\n",
        "\n",
        "model = models.Sequential([\n",
        "    layers.LSTM(128, activation='tanh', input_shape=(X_train_lstm.shape[1], X_train_lstm.shape[2])),\n",
        "    layers.Dense(64, activation='relu'),\n",
        "    layers.Dense(3, activation='softmax')\n",
        "])\n",
        "\n",
        "model.compile(optimizer=Adam(),\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "history = model.fit(\n",
        "    X_train_lstm, y_train_int,\n",
        "    epochs=20,\n",
        "    batch_size=32,\n",
        "    validation_data=(X_test_lstm, y_test_int),\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "\n",
        "loss, acc = model.evaluate(X_test_lstm, y_test_int, verbose=0)\n",
        "print(f\"Test loss: {loss:.4f}\")\n",
        "print(f\"Test accuracy: {acc:.4f}\")\n",
        "\n",
        "y_pred_probs = model.predict(X_test_lstm, verbose=0)\n",
        "y_pred = np.argmax(y_pred_probs, axis=1)\n",
        "\n",
        "y_true = y_test_int\n",
        "\n",
        "cm = confusion_matrix(y_true, y_pred)\n",
        "print(classification_report(y_true, y_pred, digits=4))\n",
        "\n",
        "class_names = [f\"Class {i}\" for i in range(3)]\n",
        "\n",
        "plt.figure(figsize=(6, 5))\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
        "            xticklabels=class_names, yticklabels=class_names)\n",
        "plt.xlabel(\"Predicted label\")\n",
        "plt.ylabel(\"True label\")\n",
        "plt.title(\"Confusion Matrix\")\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0JR4YeWeBzvG"
      },
      "source": [
        "## Standard Scaler"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BMRheYfOBzax"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-iOO8DA1uTmI"
      },
      "outputs": [],
      "source": [
        "X_train_lstm = np.asarray(X_train_std, dtype=np.float32).reshape(X_train_std.shape[0], 1, X_train_std.shape[1])\n",
        "X_test_lstm  = np.asarray(X_test_std,  dtype=np.float32).reshape(X_test_std.shape[0],  1, X_test_std.shape[1])\n",
        "\n",
        "\n",
        "y_train_int = np.asarray(y_train, dtype=np.int32)\n",
        "y_test_int  = np.asarray(y_test,  dtype=np.int32)\n",
        "\n",
        "model = models.Sequential([\n",
        "    layers.LSTM(128, activation='tanh', input_shape=(X_train_lstm.shape[1], X_train_lstm.shape[2])),\n",
        "    layers.Dense(64, activation='relu'),\n",
        "    layers.Dense(3, activation='softmax')\n",
        "])\n",
        "\n",
        "model.compile(optimizer=Adam(),\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "history = model.fit(\n",
        "    X_train_lstm, y_train_int,\n",
        "    epochs=20,\n",
        "    batch_size=32,\n",
        "    validation_data=(X_test_lstm, y_test_int),\n",
        "    verbose=1\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y-JdyLSE5rWJ"
      },
      "outputs": [],
      "source": [
        "loss, acc = model.evaluate(X_test_lstm, y_test_int, verbose=0)\n",
        "print(f\"Test loss: {loss:.4f}\")\n",
        "print(f\"Test accuracy: {acc:.4f}\")\n",
        "\n",
        "y_pred_probs = model.predict(X_test_lstm, verbose=0)\n",
        "y_pred = np.argmax(y_pred_probs, axis=1)\n",
        "\n",
        "y_true = y_test_int\n",
        "\n",
        "cm = confusion_matrix(y_true, y_pred)\n",
        "print(classification_report(y_true, y_pred, digits=4))\n",
        "\n",
        "class_names = [f\"Class {i}\" for i in range(3)]\n",
        "\n",
        "plt.figure(figsize=(6, 5))\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
        "            xticklabels=class_names, yticklabels=class_names)\n",
        "plt.xlabel(\"Predicted label\")\n",
        "plt.ylabel(\"True label\")\n",
        "plt.title(\"Confusion Matrix\")\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KjCA-WDXE8Bl"
      },
      "source": [
        "## Downsampling"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JnIhKwONFBDp"
      },
      "outputs": [],
      "source": [
        "X_train_lstm = np.asarray(X_train_downsampled, dtype=np.float32).reshape(X_train_downsampled.shape[0], 1, X_train_downsampled.shape[1])\n",
        "X_test_lstm  = np.asarray(X_test,  dtype=np.float32).reshape(X_test.shape[0],  1, X_test.shape[1])\n",
        "\n",
        "\n",
        "y_train_int = np.asarray(y_train_downsampled, dtype=np.int32)\n",
        "y_test_int  = np.asarray(y_test,  dtype=np.int32)\n",
        "\n",
        "model = models.Sequential([\n",
        "    layers.LSTM(128, activation='tanh', input_shape=(X_train_lstm.shape[1], X_train_lstm.shape[2])),\n",
        "    layers.Dense(64, activation='relu'),\n",
        "    layers.Dense(3, activation='softmax')\n",
        "])\n",
        "\n",
        "model.compile(optimizer=Adam(),\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "history = model.fit(\n",
        "    X_train_lstm, y_train_int,\n",
        "    epochs=20,\n",
        "    batch_size=32,\n",
        "    validation_data=(X_test_lstm, y_test_int),\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "\n",
        "loss, acc = model.evaluate(X_test_lstm, y_test_int, verbose=0)\n",
        "print(f\"Test loss: {loss:.4f}\")\n",
        "print(f\"Test accuracy: {acc:.4f}\")\n",
        "\n",
        "y_pred_probs = model.predict(X_test_lstm, verbose=0)\n",
        "y_pred = np.argmax(y_pred_probs, axis=1)\n",
        "\n",
        "y_true = y_test_int\n",
        "\n",
        "cm = confusion_matrix(y_true, y_pred)\n",
        "print(classification_report(y_true, y_pred, digits=4))\n",
        "\n",
        "class_names = [f\"Class {i}\" for i in range(3)]\n",
        "\n",
        "\n",
        "plt.figure(figsize=(6, 5))\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
        "            xticklabels=class_names, yticklabels=class_names)\n",
        "plt.xlabel(\"Predicted label\")\n",
        "plt.ylabel(\"True label\")\n",
        "plt.title(\"Confusion Matrix\")\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vZp0eoHTFC7f"
      },
      "source": [
        "## Oversampling"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KcxafqpmFHiY"
      },
      "outputs": [],
      "source": [
        "X_train_lstm = np.asarray(X_train_oversampled, dtype=np.float32).reshape(X_train_oversampled.shape[0], 1, X_train_oversampled.shape[1])\n",
        "X_test_lstm  = np.asarray(X_test,  dtype=np.float32).reshape(X_test.shape[0],  1, X_test.shape[1])\n",
        "\n",
        "y_train_int = np.asarray(y_train_oversampled, dtype=np.int32)\n",
        "y_test_int  = np.asarray(y_test,  dtype=np.int32)\n",
        "\n",
        "model = models.Sequential([\n",
        "    layers.LSTM(128, activation='tanh', input_shape=(X_train_lstm.shape[1], X_train_lstm.shape[2])),\n",
        "    layers.Dense(64, activation='relu'),\n",
        "    layers.Dense(3, activation='softmax')\n",
        "])\n",
        "\n",
        "model.compile(optimizer=Adam(),\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "history = model.fit(\n",
        "    X_train_lstm, y_train_int,\n",
        "    epochs=20,\n",
        "    batch_size=32,\n",
        "    validation_data=(X_test_lstm, y_test_int),\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "loss, acc = model.evaluate(X_test_lstm, y_test_int, verbose=0)\n",
        "print(f\"Test loss: {loss:.4f}\")\n",
        "print(f\"Test accuracy: {acc:.4f}\")\n",
        "\n",
        "y_pred_probs = model.predict(X_test_lstm, verbose=0)\n",
        "y_pred = np.argmax(y_pred_probs, axis=1)\n",
        "\n",
        "y_true = y_test_int\n",
        "\n",
        "cm = confusion_matrix(y_true, y_pred)\n",
        "print(classification_report(y_true, y_pred, digits=4))\n",
        "\n",
        "class_names = [f\"Class {i}\" for i in range(3)]\n",
        "\n",
        "plt.figure(figsize=(6, 5))\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
        "            xticklabels=class_names, yticklabels=class_names)\n",
        "plt.xlabel(\"Predicted label\")\n",
        "plt.ylabel(\"True label\")\n",
        "plt.title(\"Confusion Matrix\")\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "umK1eRZF0D1a"
      },
      "outputs": [],
      "source": [
        "X_train_lstm = np.asarray(X_train_oversampled, dtype=np.float32).reshape(X_train_oversampled.shape[0], 1, X_train_oversampled.shape[1])\n",
        "X_test_lstm  = np.asarray(X_test,  dtype=np.float32).reshape(X_test.shape[0],  1, X_test.shape[1])\n",
        "\n",
        "\n",
        "y_train_int = np.asarray(y_train_oversampled, dtype=np.int32)\n",
        "y_test_int  = np.asarray(y_test,  dtype=np.int32)\n",
        "\n",
        "model = models.Sequential([\n",
        "    layers.LSTM(128, activation='tanh', input_shape=(X_train_lstm.shape[1], X_train_lstm.shape[2])),\n",
        "    layers.Dense(64, activation='relu'),\n",
        "    layers.Dense(3, activation='softmax')\n",
        "])\n",
        "\n",
        "model.compile(optimizer=Adam(),\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "history = model.fit(\n",
        "    X_train_lstm, y_train_int,\n",
        "    epochs=20,\n",
        "    batch_size=32,\n",
        "    validation_data=(X_test_lstm, y_test_int),\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "loss, acc = model.evaluate(X_test_lstm, y_test_int, verbose=0)\n",
        "print(f\"Test loss: {loss:.4f}\")\n",
        "print(f\"Test accuracy: {acc:.4f}\")\n",
        "\n",
        "y_pred_probs = model.predict(X_test_lstm, verbose=0)\n",
        "y_pred = np.argmax(y_pred_probs, axis=1)\n",
        "\n",
        "y_true = y_test_int\n",
        "\n",
        "cm = confusion_matrix(y_true, y_pred)\n",
        "print(classification_report(y_true, y_pred, digits=4))\n",
        "\n",
        "class_names = [f\"Class {i}\" for i in range(3)]\n",
        "\n",
        "plt.figure(figsize=(6, 5))\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
        "            xticklabels=class_names, yticklabels=class_names)\n",
        "plt.xlabel(\"Predicted label\")\n",
        "plt.ylabel(\"True label\")\n",
        "plt.title(\"Confusion Matrix\")\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j5-LnJLpjIJf"
      },
      "source": [
        "# Anomaly Detection - hybrid approach + GUI"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Mnh-U68aNgVs"
      },
      "outputs": [],
      "source": [
        "# Isolation Forest on training data\n",
        "iso = IsolationForest(contamination=0.05, random_state=42)\n",
        "iso.fit(X_train)\n",
        "\n",
        "X_train_aug = X_train.copy()\n",
        "X_test_aug  = X_test.copy()\n",
        "\n",
        "X_train_aug['iso_score'] = iso.decision_function(X_train_aug)\n",
        "X_test_aug['iso_score'] = iso.decision_function(X_test_aug)\n",
        "\n",
        "# Save list of feature columns\n",
        "feature_list = list(X_train_aug.columns)\n",
        "joblib.dump(feature_list, \"/content/drive/MyDrive/Dataset/Model/features.pkl\")\n",
        "\n",
        "# Random Forest classifier\n",
        "clf = RandomForestClassifier(class_weight='balanced', random_state=42)\n",
        "clf.fit(X_train_aug, y_train)\n",
        "\n",
        "y_pred = clf.predict(X_test_aug)\n",
        "\n",
        "print(classification_report(y_test, y_pred))\n",
        "print(confusion_matrix(y_test, y_pred))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S2r9UGQwzOPx"
      },
      "outputs": [],
      "source": [
        "# Get model predictions\n",
        "y_pred = clf.predict(X_test_aug)\n",
        "y_true = y_test\n",
        "\n",
        "# Confusion matrix\n",
        "cm = confusion_matrix(y_true, y_pred)\n",
        "\n",
        "# Classification report\n",
        "print(classification_report(y_true, y_pred))\n",
        "\n",
        "# Plot confusion matrix\n",
        "plt.figure(figsize=(6, 5))\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
        "            xticklabels=[f\"Class {i}\" for i in range(len(set(y_true)))],\n",
        "            yticklabels=[f\"Class {i}\" for i in range(len(set(y_true)))])\n",
        "plt.xlabel(\"Predicted Label\")\n",
        "plt.ylabel(\"True Label\")\n",
        "plt.title(\"Confusion Matrix - Random Forest with Isolation Forest feature\")\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R19yVG9cXPAV"
      },
      "outputs": [],
      "source": [
        "joblib.dump(iso, \"/content/drive/MyDrive/Dataset/Model/isolation_forest.pkl\")\n",
        "joblib.dump(clf, \"/content/drive/MyDrive/Dataset/Model/rf_classifier.pkl\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load trained models\n",
        "iso = joblib.load(\"/content/drive/MyDrive/Dataset/Model/isolation_forest.pkl\")\n",
        "clf = joblib.load(\"/content/drive/MyDrive/Dataset/Model/rf_classifier.pkl\")\n",
        "\n",
        "# Define labels mapping\n",
        "label_map = {0: \"Benign\", 1: \"Malicious\", 2: \"NonDoH\"}\n",
        "\n",
        "train_features = ['PacketLengthSkewFromMode', 'FlowSentRate', 'PacketTimeVariance',\n",
        "       'ResponseTimeTimeStandardDeviation', 'FlowBytesReceived',\n",
        "       'ResponseTimeTimeCoefficientofVariation', 'PacketLengthMode',\n",
        "       'PacketTimeMedian', 'PacketTimeMode', 'PacketLengthVariance',\n",
        "       'ResponseTimeTimeMedian', 'PacketLengthCoefficientofVariation',\n",
        "       'PacketTimeMean', 'PacketTimeSkewFromMedian',\n",
        "       'PacketTimeCoefficientofVariation', 'ResponseTimeTimeSkewFromMedian',\n",
        "       'ResponseTimeTimeSkewFromMode', 'PacketLengthMedian',\n",
        "       'PacketTimeSkewFromMode', 'PacketLengthMean', 'ResponseTimeTimeMean',\n",
        "       'FlowBytesSent', 'Duration', 'PacketLengthSkewFromMedian',\n",
        "       'PacketTimeStandardDeviation', 'ResponseTimeTimeVariance',\n",
        "       'ResponseTimeTimeMode', 'FlowReceivedRate',\n",
        "       'PacketLengthStandardDeviation']\n",
        "\n",
        "# Function to handle uploaded CSV\n",
        "def predict_csv(file_path):\n",
        "    # Read CSV\n",
        "    X_new = pd.read_csv(file_path)\n",
        "    X_new = X_new[train_features]\n",
        "    # Add iso_score from Isolation Forest\n",
        "    X_new[\"iso_score\"] = iso.decision_function(X_new)\n",
        "\n",
        "    # Predict\n",
        "    preds = clf.predict(X_new)\n",
        "    preds = [label_map[p] for p in preds]\n",
        "\n",
        "    # Return as dataframe for nice output\n",
        "    result = pd.DataFrame({\"Prediction\": preds})\n",
        "    print(X_new)\n",
        "    print(result)\n",
        "    return result\n",
        "\n",
        "# Gradio UI\n",
        "iface = gr.Interface(\n",
        "    fn=predict_csv,\n",
        "    inputs=gr.File(type=\"filepath\", file_types=[\".csv\"]),\n",
        "    outputs=gr.Dataframe(),\n",
        "    title=\"Hybrid Anomaly Detection + Classification\",\n",
        "    description=\"Upload X_test.csv to get predictions (NonDoH, Benign, Malicious).\"\n",
        ")\n",
        "\n",
        "iface.launch(share=True)"
      ],
      "metadata": {
        "id": "dGGlYS7J0CoO"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}